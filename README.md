# Memorizer TypeScript - Airgapped AI Memory Service

A fully self-contained AI-powered memory service with embedded models, designed to run completely offline after installation.

## Features

- ðŸ”’ **Fully Airgapped**: No internet calls after installation
- ðŸ§  **Embedded AI Models**: Bundled nomic-embed-text (768D embeddings) + TinyLlama (1.1B LLM)
- ðŸ’¾ **Self-Contained Database**: LanceDB embedded vector database
- ðŸŽ¨ **Modern UI**: React with light/dark theme support
- ðŸ” **Semantic Search**: Vector similarity search with metadata filtering
- ðŸ“ **Auto-Title Generation**: AI-powered title suggestions
- ðŸ•’ **Full Versioning**: Complete audit trail with diff support
- ðŸ”— **Knowledge Graph**: Memory relationships and connections
- ðŸ¤– **MCP Integration**: Model Context Protocol server for AI agents

## Quick Start

### Option 1: Online Installation (npm)

For machines with internet access:

```bash
# Install and run HTTP server + Web UI
npx @leon4s4/memorizer-server start

# Or install globally
npm install -g @leon4s4/memorizer-server
memorizer start
```

On first run, models (~920MB) will be downloaded to `~/.memorizer/models/`.

### Option 2: Airgapped Installation (GitHub Release)

For completely offline/airgapped machines (no internet required):

**1. Download the bundled package:**
- Go to [Latest Release](https://github.com/Leon4s4/memorizer-ts/releases/latest)
- Download `leon4s4-memorizer-server-2.1.0.tgz` (1.2GB - includes all models)

**2. Transfer to your machine and install:**
```bash
# Skip optional dependencies (prevents sharp from downloading binaries)
npm install --no-optional ./leon4s4-memorizer-server-2.1.0.tgz

# Or with global install
npm install --no-optional -g ./leon4s4-memorizer-server-2.1.0.tgz
```

> **Important**: Use `--no-optional` flag to skip sharp (image processing library) which tries to download binaries. We only use text embeddings, so sharp is not needed.

**3. Run:**
```bash
npx memorizer start
```

âœ… **Works completely offline** - no downloads, no certificate errors!

> **Note**: npm has a package size limit, so versions with bundled models (2.1.0+) are distributed via GitHub Releases instead of npm registry.

## MCP Server Setup

Memorizer provides an MCP (Model Context Protocol) server for integration with Claude Desktop, Claude Code, and other MCP clients.

### Option 1: Claude Code (CLI)

**1. Install the server globally:**
```bash
npm install -g @leon4s4/memorizer-server
```

**2. Configure MCP in `~/.claude/settings.json`:**
```json
{
  "mcpServers": {
    "memorizer": {
      "command": "memorizer",
      "args": ["mcp"],
      "env": {
        "MEMORIZER_DATA_PATH": "/Users/YOUR_USERNAME/.memorizer/data",
        "MEMORIZER_MODEL_PATH": "/Users/YOUR_USERNAME/.memorizer/models"
      }
    }
  }
}
```

**3. Restart Claude Code** - The MCP tools will be available automatically

**Available Tools:**
- `store_memory` - Save information to memory
- `search_memories` - Semantic search across memories
- `get_memory` - Retrieve memory by ID
- `update_memory` - Edit existing memory
- `delete_memory` - Remove memory
- `list_memories` - Browse all memories
- `get_memory_stats` - View statistics
- `create_relationship` - Link related memories

### Option 2: VS Code (Claude for VSCode Extension)

**1. Install the server globally:**
```bash
npm install -g @leon4s4/memorizer-server
```

**2. Open VS Code Settings (JSON):**
- Press `Cmd+Shift+P` (Mac) or `Ctrl+Shift+P` (Windows/Linux)
- Type "Preferences: Open User Settings (JSON)"
- Press Enter

**3. Add MCP server configuration:**
```json
{
  "claude.mcpServers": {
    "memorizer": {
      "command": "memorizer",
      "args": ["mcp"],
      "env": {
        "MEMORIZER_DATA_PATH": "/Users/YOUR_USERNAME/.memorizer/data",
        "MEMORIZER_MODEL_PATH": "/Users/YOUR_USERNAME/.memorizer/models"
      }
    }
  }
}
```

**4. Reload VS Code** - The MCP tools will appear in Claude's tool list

### Option 3: Claude Desktop

**1. Install the server globally:**
```bash
npm install -g @leon4s4/memorizer-server
```

**2. Configure in `~/Library/Application Support/Claude/claude_desktop_config.json` (macOS):**
```json
{
  "mcpServers": {
    "memorizer": {
      "command": "memorizer",
      "args": ["mcp"],
      "env": {
        "MEMORIZER_DATA_PATH": "/Users/YOUR_USERNAME/.memorizer/data",
        "MEMORIZER_MODEL_PATH": "/Users/YOUR_USERNAME/.memorizer/models"
      }
    }
  }
}
```

**Windows:** `%APPDATA%/Claude/claude_desktop_config.json`

**3. Restart Claude Desktop** - MCP tools will be available

### MCP Server Direct Usage

You can also run the MCP server directly for testing:

```bash
# Start MCP server (stdio mode)
memorizer mcp

# Test with MCP inspector
npx @modelcontextprotocol/inspector memorizer mcp
```

### Troubleshooting MCP Setup

**MCP tools not appearing:**
1. Verify installation: `which memorizer` (should show path)
2. Test server: `memorizer mcp` (should not error immediately)
3. Check logs in Claude/VS Code developer console
4. Ensure paths use absolute paths (no `~`)

**Models not found:**
1. Run `memorizer start` once to download models
2. Check `~/.memorizer/models/` directory exists
3. Verify `MEMORIZER_MODEL_PATH` in MCP config

**Connection issues:**
1. Restart the client application completely
2. Verify JSON syntax in config files
3. Check file permissions on `.memorizer` directory

## Development

```bash
# Clone and install dependencies
git clone <repository>
cd memorizer-ts
npm install

# Run in development mode
npm run dev

# Build for production
npm run build

# Run tests
npm run test
```

## Project Structure

```
memorizer-ts/
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ server/          # Backend (Fastify + LanceDB + AI models)
â”‚   â”œâ”€â”€ web/             # Frontend (React + Vite)
â”‚   â””â”€â”€ shared/          # Shared TypeScript types
â”œâ”€â”€ scripts/             # Build and migration scripts
â””â”€â”€ turbo.json           # Monorepo build configuration
```

## Technology Stack

### Backend
- **Fastify** - Fast HTTP server
- **LanceDB** - Embedded vector database
- **Transformers.js** - Embedding model inference
- **node-llama-cpp** - LLM inference
- **BullMQ** - Background job processing
- **@modelcontextprotocol/sdk** - MCP server

### Frontend
- **React 18** - UI framework
- **Vite** - Build tool
- **Zustand** - State management
- **shadcn/ui** - UI components
- **Tailwind CSS** - Styling

## Package Variants

### Online Variant (Default)
- **Package name**: `@leon4s4/memorizer-server`
- **Size**: ~10MB
- **Models**: Downloaded on first install to `~/.memorizer/models/`

### Offline Variant
- **Package name**: `@leon4s4/memorizer-server-offline`
- **Size**: ~1.4GB
- **Models**: Bundled in package (truly airgapped)

## CLI Commands

```bash
# Start server
memorizer start [--port 5000] [--data ~/.memorizer/data]

# Export data
memorizer export --output memories.json

# Import data
memorizer import --input memories.json

# Backup
memorizer backup --output backup.zip

# Admin operations
memorizer admin title-gen          # Generate missing titles
memorizer admin rebuild-index      # Rebuild vector indexes
```

## API Endpoints

### REST API
- `GET /api/memories` - List memories
- `POST /api/memories` - Create memory
- `GET /api/memories/:id` - Get memory by ID
- `PUT /api/memories/:id` - Update memory
- `DELETE /api/memories/:id` - Delete memory
- `POST /api/search` - Semantic search

### Web UI
- `http://localhost:5000/ui` - Web interface

### MCP Server
- `stdio` mode for Claude Desktop, Claude Code, VS Code
- Tools: store, search, get, update, delete, list, stats, relationships
- See [MCP Server Setup](#mcp-server-setup) section above

## Configuration

Configuration is stored in `~/.memorizer/config.json` or via environment variables:

```bash
# Server
MEMORIZER_PORT=5000
MEMORIZER_DATA_PATH=~/.memorizer/data

# Models
MEMORIZER_MODEL_PATH=~/.memorizer/models
```

## Performance

- **Embedding generation**: <100ms per 512 tokens
- **Vector search**: <50ms for 10k memories
- **Title generation**: <10s per memory
- **Memory footprint**: ~2GB (models + runtime)

## Migration from v1 (.NET/PostgreSQL)

See [MIGRATION.md](./MIGRATION.md) for detailed migration guide from the .NET version.

## License

MIT

## Credits

Built with:
- [LanceDB](https://lancedb.com/) - Embedded vector database
- [Transformers.js](https://huggingface.co/docs/transformers.js) - ML models in JS
- [node-llama-cpp](https://withcatai.github.io/node-llama-cpp/) - LLM inference
- [Model Context Protocol](https://modelcontextprotocol.io/) - AI agent integration
